{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 常用中文分词库用法示例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本 Notebook 包含如下几个常用中文分词库的使用示例：\n",
    "\n",
    "- jieba\n",
    "- NLPIR\n",
    "- pkuseg\n",
    "- THULAC\n",
    "- Baidu LAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:\n",
      "我能吞下玻璃而不伤身体是由 Ethan Mollick 在早期互联网上发起的语言学项目。该项目的目的是收集不同语言中「我能吞下玻璃而不伤身体」这句话的翻译。该项目的原始网页于 2004 年消失。\n",
      "Mollick 解释道，旅行者到达外国时，会有一种「不可抑制的冲动」想要用当地语言说些什么，但无论说什么都会让当地人认为他只是个游客。但是，如果旅行者能用地道的当地语言说一句类似「我能吞下玻璃而不伤身体」这样不同寻常的话，则能让旅行者「获得当地人的尊重」。\n",
      "该项目在志愿者的贡献下增长到超过 150 种语言，包括不少人造或虚构语言，以及多种计算机语言。它最终变成了一个网络模因。\n",
      "\n",
      "Text length: 287\n"
     ]
    }
   ],
   "source": [
    "# read example text\n",
    "with open(\"resources/i-can-eat-glass.txt\") as f:\n",
    "    text = f.read()\n",
    "print(\"Text:\\n{}\\n\\nText length: {}\".format(text, len(text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## jieba\n",
    "\n",
    "Docs: https://github.com/fxsjy/jieba#主要功能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jieba.cut() returns: <generator object Tokenizer.cut at 0x7fc1cc1519e0>\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "# Cut\n",
    "jieba_cut_result = jieba.cut(text)\n",
    "print(\"jieba.cut() returns: {}\".format(jieba_cut_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到 `jieba.cut()` 返回的是一个 generator 对象，可以使用 `list()` 转换成列表或者直接使用 `jieba.lcut()` 返回 list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.602 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我能/吞下/玻璃/而/不伤/身体/是/由/ /Ethan/ /Mollick/ /在/早期/互联网/上/发起/的/语言学/项目/。/该项/目的/目的/是/收集/不同/语言/中/「/我能/吞下/玻璃/而/不伤/身体/」/这句/话/的/翻译/。/该项/目的/原始/网页/于/ /2004/ /年/消失/。/\n",
      "/Mollick/ /解释/道/，/旅行者/到达/外国/时/，/会/有/一种/「/不可/抑制/的/冲动/」/想要/用/当地/语言/说些/什么/，/但/无论/说/什么/都/会/让/当地人/认为/他/只是/个/游客/。/但是/，/如果/旅行者/能/用地/道/的/当地/语言/说/一句/类似/「/我能/吞下/玻璃/而/不伤/身体/」/这样/不同寻常/的话/，/则/能/让/旅行者/「/获得/当地人/的/尊重/」/。/\n",
      "/该/项目/在/志愿者/的/贡献/下/增长/到/超过/ /150/ /种/语言/，/包括/不少/人造/或/虚构/语言/，/以及/多种/计算机/语言/。/它/最终/变成/了/一个/网络/模因/。\n"
     ]
    }
   ],
   "source": [
    "# Get a list\n",
    "jieba_cut_list = list(jieba_cut_result)  # or: jieba.lcut(text)\n",
    "print(\"/\".join(jieba_cut_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 不同的分词方法和参数\n",
    "\n",
    "根据 [源码](https://github.com/fxsjy/jieba/blob/67fa2e36e72f69d9134b8a1037b83fbb070b9775/jieba/__init__.py#L289)，可以看到 `jieba.cut()` 有三个 bool 类型的参数，分别为：\n",
    "\n",
    "- cut_all: 是否启用全模式，即尽可能找出所有词，默认为 False\n",
    "- HMM: 是否使用 HMM（隐形马尔可夫模型，多用于新词发现），默认为 True\n",
    "- use_paddle: 是否使用 [飞桨 PaddlePaddle](https://www.paddlepaddle.org.cn) 深度学习框架进行分词，默认为 False\n",
    "\n",
    "此外还有 `jieba.cut_for_search()` 函数，通过对 `jieba.cut()` 的结果进行后处理，得出更适合用于搜索引擎建立倒排索引用的细粒度分词结果。\n",
    "\n",
    "更多请查看 [GitHub 上的 README](https://github.com/fxsjy/jieba#特点)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "默认: 我能/吞下/玻璃/而/不伤/身体/是/由/ /Ethan/ /Mollick/ /在/早期/互联网/上/发起/的/语言学/项目/。/该项/目的/目的/是/收集/不同/语言/中/「/我能/吞下/玻璃/而/不伤/身体/」/这句/话/的/翻译/。/该项/目的/原始/网页/于/ /2004/ /年/消失/。/\n",
      "/Mollick/ /解释/道/，/旅行者/到达/外国/时/，/会/有/一种/「/不可/抑制/的/冲动/」/想要/用/当地/语言/说些/什么/，/但/无论/说/什么/都/会/让/当地人/认为/他/只是/个/游客/。/但是/，/如果/旅行者/能/用地/道/的/当地/语言/说/一句/类似/「/我能/吞下/玻璃/而/不伤/身体/」/这样/不同寻常/的话/，/则/能/让/旅行者/「/获得/当地人/的/尊重/」/。/\n",
      "/该/项目/在/志愿者/的/贡献/下/增长/到/超过/ /150/ /种/语言/，/包括/不少/人造/或/虚构/语言/，/以及/多种/计算机/语言/。/它/最终/变成/了/一个/网络/模因/。\n",
      "\n",
      "全模式: 我/能/吞下/玻璃/而/不伤/伤身/身体/是/由// //Ethan// //Mollick// //在/早期/互联/互联网/联网/网上/发起/的/语言/语言学/项目/。/该项/项目/目的/目的/是/收集/不同/语言/言中/「/我/能/吞下/玻璃/而/不伤/伤身/身体/」/这/句/话/的/翻译/。/该项/项目/目的/原始/网页/于// //2004// //年/消失/。/\n",
      "//Mollick// //解释/释道/，/旅行/旅行者/行者/到达/外国/时/，/会/有/一种/「/不可/可抑制/抑制/的/冲动/」/想要/要用/当地/语言/言说/些/什么/，/但/无论/论说/什么/都/会/让/当地/当地人/认为/他/只是/个/游客/。/但是/，/如果/旅行/旅行者/行者/能用/用地/地道/的/当地/语言/言说/一句/类似/「/我/能/吞下/玻璃/而/不伤/伤身/身体/」/这样/不同/不同寻常/寻常/的话/，/则/能/让/旅行/旅行者/行者/「/获得/得当/当地/当地人/的/尊重/」。/\n",
      "//该项/项目/在/志愿/志愿者/愿者/的/贡献/下/增长/到/超过// //150// //种/语言/，/包括/不少/人造/或/虚构/语言/，/以及/多种/计算/计算机/算机/语言/。/它/最终/变成/了/一个/网络/模/因/。\n",
      "\n",
      "关闭 HMM: 我/能/吞下/玻璃/而/不/伤/身体/是/由/ /Ethan/ /Mollick/ /在/早期/互联网/上/发起/的/语言学/项目/。/该项/目的/目的/是/收集/不同/语言/中/「/我/能/吞下/玻璃/而/不/伤/身体/」/这/句/话/的/翻译/。/该项/目的/原始/网页/于/ /2004/ /年/消失/。/\n",
      "/Mollick/ /解释/道/，/旅行者/到达/外国/时/，/会/有/一种/「/不可/抑制/的/冲动/」/想要/用/当地/语言/说/些/什么/，/但/无论/说/什么/都/会/让/当地人/认为/他/只是/个/游客/。/但是/，/如果/旅行者/能/用地/道/的/当地/语言/说/一句/类似/「/我/能/吞下/玻璃/而/不/伤/身体/」/这样/不同寻常/的话/，/则/能/让/旅行者/「/获得/当地人/的/尊重/」/。/\n",
      "/该/项目/在/志愿者/的/贡献/下/增长/到/超过/ /150/ /种/语言/，/包括/不少/人造/或/虚构/语言/，/以及/多种/计算机/语言/。/它/最终/变成/了/一个/网络/模/因/。\n",
      "\n",
      "飞桨: 我能/吞下/玻璃/而/不伤/身体/是/由/ /Ethan/ /Mollick/ /在/早期/互联网/上/发起/的/语言学/项目/。/该项/目的/目的/是/收集/不同/语言/中/「/我能/吞下/玻璃/而/不伤/身体/」/这句/话/的/翻译/。/该项/目的/原始/网页/于/ /2004/ /年/消失/。/\n",
      "/Mollick/ /解释/道/，/旅行者/到达/外国/时/，/会/有/一种/「/不可/抑制/的/冲动/」/想要/用/当地/语言/说些/什么/，/但/无论/说/什么/都/会/让/当地人/认为/他/只是/个/游客/。/但是/，/如果/旅行者/能/用地/道/的/当地/语言/说/一句/类似/「/我能/吞下/玻璃/而/不伤/身体/」/这样/不同寻常/的话/，/则/能/让/旅行者/「/获得/当地人/的/尊重/」/。/\n",
      "/该/项目/在/志愿者/的/贡献/下/增长/到/超过/ /150/ /种/语言/，/包括/不少/人造/或/虚构/语言/，/以及/多种/计算机/语言/。/它/最终/变成/了/一个/网络/模因/。\n",
      "\n",
      "搜索引擎: 我能/吞下/玻璃/而/不伤/身体/是/由/ /Ethan/ /Mollick/ /在/早期/互联/联网/互联网/上/发起/的/语言/语言学/项目/。/该项/目的/目的/是/收集/不同/语言/中/「/我能/吞下/玻璃/而/不伤/身体/」/这句/话/的/翻译/。/该项/目的/原始/网页/于/ /2004/ /年/消失/。/\n",
      "/Mollick/ /解释/道/，/旅行/行者/旅行者/到达/外国/时/，/会/有/一种/「/不可/抑制/的/冲动/」/想要/用/当地/语言/说些/什么/，/但/无论/说/什么/都/会/让/当地/当地人/认为/他/只是/个/游客/。/但是/，/如果/旅行/行者/旅行者/能/用地/道/的/当地/语言/说/一句/类似/「/我能/吞下/玻璃/而/不伤/身体/」/这样/不同/寻常/不同寻常/的话/，/则/能/让/旅行/行者/旅行者/「/获得/当地/当地人/的/尊重/」/。/\n",
      "/该/项目/在/志愿/愿者/志愿者/的/贡献/下/增长/到/超过/ /150/ /种/语言/，/包括/不少/人造/或/虚构/语言/，/以及/多种/计算/算机/计算机/语言/。/它/最终/变成/了/一个/网络/模因/。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = [\n",
    "    ('默认', jieba.cut(text)),\n",
    "    ('全模式', jieba.cut(text, cut_all=True)),\n",
    "    ('关闭 HMM', jieba.cut(text, HMM=False)),\n",
    "    ('飞桨', jieba.cut(text, use_paddle=True)),\n",
    "    ('搜索引擎', jieba.cut_for_search(text))\n",
    "]\n",
    "for r in results:\n",
    "    print(\"{}: {}\\n\".format(r[0], \"/\".join(list(r[1]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自定义词典\n",
    "\n",
    "可以看到，jieba 的默认词表无法正确切分「该项目的目的」为「该 / 项目 / 的 / 目的」，也无法正确认出「能用地道的当地语言」中的「地道」。\n",
    "\n",
    "jieba 提供了自定义词典的功能以提高分词准确率。详细用法可以参考: [载入词典](https://github.com/fxsjy/jieba#载入词典)。\n",
    "\n",
    "此外还可以用 `jieba.add_word()` `jieba.del_word()` 来在线调整词典，其用法为：\n",
    "\n",
    "- `jieba.add_word(\"word\", freq, tag)`: `freq` 为词频，`tag` 为词性\n",
    "- `jieba.del_word(\"word\")`: 从词典中移除该单词，该方法等同于将词频设置为 `0`\n",
    "\n",
    "此外，`jieba.suggest_freq()` 可以用来调整单个词的词频，使得：\n",
    "\n",
    "- 一个词可以被分出来: `jieba.suggest_freq(\"word\", tune=True)`\n",
    "- 一个词不会被分出来: `jieba.suggest_freq((\"wo\", \"rd\"), tune=True)`\n",
    "\n",
    "若 `tune=False`，那么 `jieba.suggest_freq()` 仅会返回一个推荐的词频数值而不设置。可以手动调用 `jieba.add_word(\"word\", freq)` 来调整词频到推荐值。\n",
    "\n",
    "详细用法和效果可以参考 [调整词典](https://github.com/fxsjy/jieba#调整词典)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我能/吞下/玻璃/而/不伤/身体/是/由/ /Ethan/ /Mollick/ /在/早期/互联网/上/发起/的/语言学/项目/。/该/项目/的/目的/是/收集/不同/语言/中/「/我能/吞下/玻璃/而/不伤/身体/」/这句/话/的/翻译/。/该/项目/的/原始/网页/于/ /2004/ /年/消失/。/\n",
      "/Mollick/ /解释/道/，/旅行者/到达/外国/时/，/会/有/一种/「/不可/抑制/的/冲动/」/想要/用/当地/语言/说些/什么/，/但/无论/说/什么/都/会/让/当地人/认为/他/只是/个/游客/。/但是/，/如果/旅行者/能/用/地道/的/当地/语言/说/一句/类似/「/我能/吞下/玻璃/而/不伤/身体/」/这样/不同寻常/的话/，/则/能/让/旅行者/「/获得/当地人/的/尊重/」/。/\n",
      "/该/项目/在/志愿者/的/贡献/下/增长/到/超过/ /150/ /种/语言/，/包括/不少/人造/或/虚构/语言/，/以及/多种/计算机/语言/。/它/最终/变成/了/一个/网络/模因/。\n"
     ]
    }
   ],
   "source": [
    "jieba.add_word(\"项目\", 100000)\n",
    "jieba.add_word(\"地道\", 1000)\n",
    "print(\"/\".join(jieba.lcut(text, HMM=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLPIR\n",
    "\n",
    "[NLPIR-ICTCLAS 汉语分词系统](http://ictclas.nlpir.org) 是 [NLPIR 大数据搜索与挖掘实验室](http://www.nlpir.org/wordpress/) 出品的软件包，支持中英文分词、词性标注、关键词提取等功能。[PyNLPIR](https://github.com/tsroten/pynlpir) 是该系统的一个 Python 接口包装。\n",
    "\n",
    "`pynlpir` 的接口非常简单，首先调用 `pynlpir.open()` 执行初始化，然后使用 `pynlpir.segment(text)` 即可执行分词操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('我', 'pronoun'), ('能', 'verb'), ('吞', 'verb'), ('下', 'verb'), ('玻璃', 'noun'), ('而', 'conjunction'), ('不', 'adverb'), ('伤', 'verb'), ('身体', 'noun'), ('是', 'verb'), ('由', 'preposition'), (' ', None), ('Ethan', 'noun'), (' ', None), ('Mollick', 'noun'), (' ', None), ('在', 'preposition'), ('早期', 'time word'), ('互联网', 'noun'), ('上', 'noun of locality')]\n"
     ]
    }
   ],
   "source": [
    "import pynlpir\n",
    "pynlpir.open()  # You can specify text encoding here, see docs for more details\n",
    "nlpir_result = pynlpir.segment(text)\n",
    "print(nlpir_result[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到 `pynlpir` 顺便把词性标注也给做了。可以通过参数来修改 `segment()` 的输出行为：\n",
    "\n",
    "- pos_tagging: 是否标注词性。默认为 `True`\n",
    "- pos_names: 标注词性的方法。默认为 `\"parent\"`，意为采用通用的词性分类。其他参数取值例如 `\"child\"`，意为采取细粒度的词性分类。\n",
    "- pos_english: 使用英文词性名称。如果为 `False`，那么词性会显示为中文，例如 `noun` 会写作 `名词`。默认为 `True`。\n",
    "\n",
    "详细参考 [文档](https://pynlpir.readthedocs.io/en/latest/api.html#pynlpir.segment)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我, pronoun, personal pronoun, 人称代词\n",
      "能, verb, verb, 动词\n",
      "吞, verb, verb, 动词\n",
      "下, verb, directional verb, 趋向动词\n",
      "玻璃, noun, noun, 名词\n",
      "而, conjunction, coordinating conjunction, 并列连词\n",
      "不, adverb, adverb, 副词\n",
      "伤, verb, verb, 动词\n",
      "身体, noun, noun, 名词\n",
      "是, verb, verb 是, 动词\"是\"\n"
     ]
    }
   ],
   "source": [
    "nlpir_result_child = pynlpir.segment(text, pos_names=\"child\")\n",
    "nlpir_result_child_cn = pynlpir.segment(text, pos_names=\"child\", pos_english=False)\n",
    "for orig, child, child_cn, _ in zip(nlpir_result, nlpir_result_child, nlpir_result_child_cn, range(10)):\n",
    "    print(\"{}, {}, {}, {}\".format(orig[0], orig[1], child[1], child_cn[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我/能/吞/下/玻璃/而/不/伤/身体/是/由/ /Ethan/ /Mollick/ /在/早期/互联网/上/发起/的/语言学/项目/。/该/项目/的/目的/是/收集/不同/语言/中/「/我/能/吞/下/玻璃/而/不/伤/身体/」/这/句/话/的/翻译/。/该/项目/的/原始/网页/于/ /2004/ /年/消失/。/\n",
      "Mollick/ /解释/道/，/旅行者/到达/外国/时/，/会/有/一/种/「/不可/抑制/的/冲动/」/想/要/用/当地/语言/说/些/什么/，/但/无论/说/什么/都/会/让/当地人/认为/他/只/是/个/游客/。/但是/，/如果/旅行者/能/用/地道/的/当地/语言/说/一/句/类似/「/我/能/吞/下/玻璃/而/不/伤/身体/」/这样/不同寻常/的/话/，/则/能/让/旅行者/「/获得/当地人/的/尊重/」/。/\n",
      "该/项目/在/志愿者/的/贡献/下/增长/到/超过/ /150/ /种/语言/，/包括/不少/人造/或/虚构/语言/，/以及/多/种/计算机/语言/。/它/最终/变成/了/一个/网络/模/因/。\n"
     ]
    }
   ],
   "source": [
    "print(\"/\".join(pynlpir.segment(text, pos_tagging=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以看到，最后一句话「网络模因」中的「模因」没有被当成一个词来处理。解决这个问题的办法仍然是自定义词典。`pynlpir` 是 Python 对 C 库的一个封装，添加用户词库的功能是作为底层 API 暴露在 `pynlpir.nlpir` 模块内，对应的函数为 `pynlpir.nlpir.AddUserWord()`，接受的是一个 `const char*` 类型的参数，因此需要把 Python 的字符串编码成 Byte Array 才可以传入。\n",
    "\n",
    "在调用 `str.encode()` 时需要指定编码，默认为 UTF-8，而 NLPIR 的默认编码同样为 UTF-8，这样就省去了指定参数的步骤。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我/能/吞/下/玻璃/而/不/伤/身体/是/由/ /Ethan/ /Mollick/ /在/早期/互联网/上/发起/的/语言学/项目/。/该/项目/的/目的/是/收集/不同/语言/中/「/我/能/吞/下/玻璃/而/不/伤/身体/」/这/句/话/的/翻译/。/该/项目/的/原始/网页/于/ /2004/ /年/消失/。/\n",
      "Mollick/ /解释/道/，/旅行者/到达/外国/时/，/会/有/一/种/「/不可/抑制/的/冲动/」/想/要/用/当地/语言/说/些/什么/，/但/无论/说/什么/都/会/让/当地人/认为/他/只/是/个/游客/。/但是/，/如果/旅行者/能/用/地道/的/当地/语言/说/一/句/类似/「/我/能/吞/下/玻璃/而/不/伤/身体/」/这样/不同寻常/的/话/，/则/能/让/旅行者/「/获得/当地人/的/尊重/」/。/\n",
      "该/项目/在/志愿者/的/贡献/下/增长/到/超过/ /150/ /种/语言/，/包括/不少/人造/或/虚构/语言/，/以及/多/种/计算机/语言/。/它/最终/变成/了/一个/网络/模因/。\n"
     ]
    }
   ],
   "source": [
    "pynlpir.nlpir.AddUserWord(\"模因\".encode())\n",
    "print(\"/\".join(pynlpir.segment(text, pos_tagging=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到「模因」已经作为一个词被正确处理了。NLPIR-ICICLAS 还提供了关键词提取、从文件中进行分词等功能，详细可以查看 [`pynlpir` 的 API 文档](https://pynlpir.readthedocs.io/en/latest/api.html#pynlpir.nlpir.Init) 和 [NLPIR-ICTCLAS 的接口文档](https://github.com/NLPIR-team/NLPIR/tree/master/NLPIR%20SDK/NLPIR-ICTCLAS/doc)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pkuseg\n",
    "\n",
    "[pkuseg](https://github.com/lancopku/pkuseg-python) 是北京大学语言计算与机器学习研究组发布的一款支持细分领域分词的工具包。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
